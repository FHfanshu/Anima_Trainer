# Anima LoRA Trainer 配置模板
# 使用方法: python anima_train.py --config ./config/train_template.yaml

# ============================================================================
# 模型路径（相对或绝对路径）
# ============================================================================
transformer_path: "models/transformers/anima-preview.safetensors"
vae_path: "models/vae/qwen_image_vae.safetensors"
text_encoder_path: "models/text_encoders"
t5_tokenizer_path: null  # 可选，留空则自动下载 google/t5-v1_1-xxl

# ============================================================================
# 数据集
# ============================================================================
data_dir: "./dataset"
resolution: 1024
repeats: 1
shuffle_caption: false
keep_tokens: 0
flip_augment: false
cache_latents: true    # 缓存 VAE latent 到 npz 文件，加速训练

# ============================================================================
# LoRA 配置
# ============================================================================
lora_type: "lokr"      # lora 或 lokr
lora_rank: 32
lora_alpha: 32.0
lokr_factor: 8

# ============================================================================
# 训练参数
# ============================================================================
epochs: 10
max_steps: 0           # 0=无限制
batch_size: 1
grad_accum: 1
learning_rate: 1.0e-4
mixed_precision: "bf16"
grad_checkpoint: true
xformers: true         # 启用 xformers memory efficient attention
num_workers: 0

# ============================================================================
# 输出与保存
# ============================================================================
output_dir: "./output"
output_name: "anima_lora"
save_every: 0          # 每 N 个 epoch 保存 (0=仅结束时)
seed: 42

# ============================================================================
# 采样
# ============================================================================
sample_every: 0        # 每 N 个 epoch 采样 (0=禁用)
sample_prompt: "1girl, masterpiece"

# ============================================================================
# 进度显示
# ============================================================================
loss_curve_steps: 100
no_progress: false
